{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W3_Homework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPWrUo6o6sridjC3smCD5r8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CIS-522/course-content/blob/main/tutorials/W3_MLPs/W3_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_li9itVYjjpg"
      },
      "source": [
        "# CIS-522 Week 3 Homework\r\n",
        "\r\n",
        "\r\n",
        "**Instructor:** Konrad Kording\r\n",
        "\r\n",
        "**Content Creators:** Arash Ash, Jordan Lei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOoyXdCFijaM",
        "cellView": "form"
      },
      "source": [
        "#@markdown What is your Pennkey and pod? (text, not numbers, e.g. bfranklin)\r\n",
        "my_pennkey = 'value' #@param {type:\"string\"}\r\n",
        "my_pod = 'euclidean-wombat' #@param ['Select', 'euclidean-wombat', 'sublime-newt', 'buoyant-unicorn', 'lackadaisical-manatee','indelible-stingray','superfluous-lyrebird','discreet-reindeer','quizzical-goldfish','ubiquitous-cheetah','nonchalant-crocodile','fashionable-lemur','spiffy-eagle','electric-emu','quotidian-lion','astute-jellyfish', 'quantum-herring']\r\n",
        "\r\n",
        "# start timing\r\n",
        "import time\r\n",
        "try:t0;\r\n",
        "except NameError: t0 = time.time()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWOc48yQrvUI"
      },
      "source": [
        "---\r\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLNTKY8sEUj"
      },
      "source": [
        "# imports\r\n",
        "import os\r\n",
        "import csv\r\n",
        "import json\r\n",
        "import random\r\n",
        "import pathlib\r\n",
        "\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision.datasets import ImageFolder\r\n",
        "from torch.utils.data import DataLoader, TensorDataset\r\n",
        "from torchvision.utils import make_grid\r\n",
        "from IPython.display import HTML, display\r\n",
        "\r\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "dev, torch.get_num_threads()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCEnJU8StUzq",
        "cellView": "form"
      },
      "source": [
        "# @title Install Kaggle API\r\n",
        "%%capture\r\n",
        "!pip install kaggle==1.5.10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFpjwPq78MdR",
        "cellView": "form"
      },
      "source": [
        "# @title Helper functions\r\n",
        "def imshow(img):\r\n",
        "    img = img / 2 + 0.5     # unnormalize\r\n",
        "    npimg = img.numpy()\r\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "    plt.axis(False)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "def progress(epoch, loss, epochs=100):\r\n",
        "    return HTML(\"\"\"\r\n",
        "        <label for=\"file\">Training loss: {loss}</label>\r\n",
        "        <progress\r\n",
        "            value='{epoch}'\r\n",
        "            max='{epochs}',\r\n",
        "            style='width: 100%'\r\n",
        "        >\r\n",
        "            {epoch}\r\n",
        "        </progress>\r\n",
        "    \"\"\".format(loss=loss, epoch=epoch, epochs=epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxpHO4kBkU3e"
      },
      "source": [
        "## Part 1. Kaggle Competition\r\n",
        "To use the Kaggle API, sign up for a Kaggle account at https://www.kaggle.com. Then go to the 'Account' tab of your user profile (`https://www.kaggle.com/<username>/account`) and select 'Create API Token'. This will trigger the download of `kaggle.json`, a file containing your API credentials. Place this file in Colab Files on the left menu.\r\n",
        "\r\n",
        "Then join the competition and accept the rules at https://www.kaggle.com/c/permuted-animal-faces/rules.\r\n",
        "Now we can handle the submisions here using the Kaggle API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfDMhvNwzTxx"
      },
      "source": [
        "# reegistering your API key\r\n",
        "!mkdir ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D0MvzgrzioP"
      },
      "source": [
        "!kaggle competitions download -c permuted-animal-faces\r\n",
        "!unzip permuted-animal-faces.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt270XcTDaRH"
      },
      "source": [
        "Now it's your turn to train a competitive model using what you learned about MLPs and show it off to the rest of the world in the Kaggle leaderboard.\r\n",
        "\r\n",
        "Here we provided you the same code as in the tutorial and the submission code, which you can run and get a baseline result. But we encourage you to get creative and combine your previous ML know-how since nothing is off the table in this competition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFSQh1demt0n"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self, actv, num_inputs, hidden_units, num_outputs):\r\n",
        "        super(Net, self).__init__()\r\n",
        "\r\n",
        "        exec('self.actv = nn.%s'%actv)   # [TO-DO]\r\n",
        "\r\n",
        "        self.layers = nn.ModuleList()\r\n",
        "        for i in range(len(hidden_units)):\r\n",
        "          next_num_inputs = hidden_units[i] \r\n",
        "          self.layers += [nn.Linear(num_inputs, next_num_inputs)]   # [TO-DO]\r\n",
        "          num_inputs = next_num_inputs\r\n",
        "\r\n",
        "        self.out = nn.Linear(num_inputs, num_outputs)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # flattening\r\n",
        "        x = x.view(x.shape[0], -1)   # [TO-DO]\r\n",
        "\r\n",
        "        for layer in self.layers:\r\n",
        "          x = self.actv(layer(x))  # [TO-DO]\r\n",
        "        x = self.out(x) # [TO-DO]\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb23NZ3l4BUB"
      },
      "source": [
        "df = pd.read_csv('train.csv')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB9gCLi65txD"
      },
      "source": [
        "data = np.array(df)\r\n",
        "X_train = torch.tensor(data[:, 1:]).float()/255\r\n",
        "y_train = torch.tensor(data[:, 0]).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laqU5kuxwOnD"
      },
      "source": [
        "batch_size = 128\r\n",
        "train_data = TensorDataset(X_train, y_train)\r\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, drop_last=True,\r\n",
        "                        shuffle=True, num_workers=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DUVNbJiwSfj"
      },
      "source": [
        "def train_test_classification(net, criterion, optimizer,\r\n",
        "                              train_loader,\r\n",
        "                              num_epochs=1, verbose=True,\r\n",
        "                              training_plot=True):\r\n",
        "  if verbose:\r\n",
        "    progress_bar = display(progress(0, 0, num_epochs), display_id=True)\r\n",
        "\r\n",
        "  net.train()   # [TO-DO]\r\n",
        "  training_losses = []\r\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\r\n",
        "      running_loss = 0.0\r\n",
        "      for i, data in enumerate(train_loader, 0):\r\n",
        "          # get the inputs; data is a list of [inputs, labels]\r\n",
        "          inputs, labels = data\r\n",
        "          inputs = inputs.to(dev).float()    # [TO-DO]\r\n",
        "          labels = labels.to(dev).long()   # [TO-DO]\r\n",
        "\r\n",
        "          # zero the parameter gradients\r\n",
        "          optimizer.zero_grad()   # [TO-DO]\r\n",
        "\r\n",
        "          # forward + backward + optimize\r\n",
        "          outputs = net(inputs)   # [TO-DO]\r\n",
        "\r\n",
        "          loss = criterion(outputs, labels)   # [TO-DO]\r\n",
        "          loss.backward()   # [TO-DO]\r\n",
        "          optimizer.step()   # [TO-DO]\r\n",
        "\r\n",
        "          # print statistics\r\n",
        "          if verbose:\r\n",
        "            training_losses += [loss.item()]\r\n",
        "            running_loss += loss.item()\r\n",
        "            if i % 10 == 9:    # update every 10 mini-batches\r\n",
        "                progress_bar.update(progress(epoch+1, running_loss / 10, num_epochs))\r\n",
        "                running_loss = 0.0\r\n",
        "\r\n",
        "  net.eval()   # [TO-DO]\r\n",
        "  def test(data_loader):\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    for data in data_loader:\r\n",
        "        inputs, labels = data\r\n",
        "        inputs = inputs.to(dev).float()\r\n",
        "        labels = labels.to(dev).long()\r\n",
        "\r\n",
        "        outputs = net(inputs)\r\n",
        "        _, predicted = torch.max(outputs, 1)   # [TO-DO]\r\n",
        "        total += labels.size(0)   # [TO-DO]\r\n",
        "        correct += (predicted == labels).sum().item()   # [TO-DO]\r\n",
        "\r\n",
        "    acc = 100 * correct / total    # [TO-DO]\r\n",
        "    return total, acc\r\n",
        "\r\n",
        "  train_total, train_acc = test(train_loader)\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "    print('Accuracy on the %d training samples: %0.2f %%' % (train_total, train_acc))\r\n",
        "\r\n",
        "  if training_plot:\r\n",
        "    plt.plot(training_losses)\r\n",
        "    plt.xlabel('Batch')\r\n",
        "    plt.ylabel('Training loss')\r\n",
        "    plt.show()\r\n",
        "  \r\n",
        "  return train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJd1-YuAwau6"
      },
      "source": [
        "net = Net('ReLU()', 3*32*32, [128, 32], 3).to(dev) \r\n",
        "criterion = nn.MultiMarginLoss(margin=1.0)\r\n",
        "optimizer = optim.Adam(net.parameters(), lr=3e-4)\r\n",
        "train_acc = train_test_classification(net, criterion, optimizer,\r\n",
        "                                      train_loader,\r\n",
        "                                      num_epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Vzhqtr7c6Y"
      },
      "source": [
        "df = pd.read_csv('test.csv')\r\n",
        "data = np.array(df)\r\n",
        "X_test = torch.tensor(data).float()/255\r\n",
        "\r\n",
        "net.eval()\r\n",
        "y_pred = net(X_test)\r\n",
        "labels_pred = torch.argmax(y_pred, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAOeoZH48OuJ"
      },
      "source": [
        "header = ['ImageId', 'Label']\r\n",
        "with open('submission.csv', 'w', newline='') as file:\r\n",
        "    writer = csv.writer(file)\r\n",
        "    writer.writerow(header)\r\n",
        "    \r\n",
        "    for i in range(len(labels_pred)):\r\n",
        "      writer.writerow([i+1] + [labels_pred[i].item()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEojRbYH9adp"
      },
      "source": [
        "!kaggle competitions submit permuted-animal-faces -f submission.csv -m \"Result with same model as in the tutorial\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_gDgatsCKJL"
      },
      "source": [
        "Note that you can submit maximum 20 times a day. Participants will need to wait until the next UTC day after submitting the maximum number of daily submissions.\r\n",
        "\r\n",
        "And finally you can hand select 2 submissions among your previous ones to be used for the final ranking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GEV3MSbDQX3"
      },
      "source": [
        "## Part 2."
      ]
    }
  ]
}
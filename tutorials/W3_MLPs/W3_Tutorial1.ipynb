{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "W3_Tutorial1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CIS-522/course-content/blob/main/tutorials/W3_MLPs/W3_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2kPrtVyXtaP"
      },
      "source": [
        "# CIS-522 Week 3 Part 1\r\n",
        "# Multi-Layer Perceptrons (MLPs)\r\n",
        "\r\n",
        "__Instructor__: Konrad Kording\r\n",
        "\r\n",
        "__Content creators:__ Arash Ash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2DuJddRXxYY"
      },
      "source": [
        "---\r\n",
        "# Tutorial Objectives\r\n",
        "In this tutorial, we delve deeper by using one of the most famous deep learning models of all!\r\n",
        "\r\n",
        "MLPs are arguably one of the most tractable models that we can use to study deep learning fundamentals. Here we will learn why MLPs are: \r\n",
        "\r\n",
        "* similar to biological networks\r\n",
        "* good at function approximation\r\n",
        "* can evolve linearly in weights \r\n",
        "* the case of deep vs. wide\r\n",
        "* dependant on transfer functions\r\n",
        "* sensitive to initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "e6GnDC12UtUD"
      },
      "source": [
        "#@markdown What is your Pennkey and pod? (text, not numbers, e.g. bfranklin)\n",
        "my_pennkey = 'value' #@param {type:\"string\"}\n",
        "my_pod = 'Select' #@param ['Select', 'euclidean-wombat', 'sublime-newt', 'buoyant-unicorn', 'lackadaisical-manatee','indelible-stingray','superfluous-lyrebird','discreet-reindeer','quizzical-goldfish','astute-jellyfish','ubiquitous-cheetah','nonchalant-crocodile','fashionable-lemur','spiffy-eagle','electric-emu','quotidian-lion']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np4EZarUtKoA"
      },
      "source": [
        "# Recap the experience from last week\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "wEdRnCm2_DT0"
      },
      "source": [
        "#@title Video: Discussing Week 2 - Linear DL\n",
        "import time\n",
        "try: t0;\n",
        "except NameError: t0=time.time()\n",
        "\n",
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "video = YouTubeVideo(id=\"xlYttP5C_LY\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew6VafSDQ7zo"
      },
      "source": [
        "We focused on linear deep learning last week. We discussed about Artificial Neural Networks and saw how it works, dynamics of learning and finally properties of high dimensional spaces. You should now have some intuition about deep learning systems we will learn. We also dived into PyTorch and autograd which are tools that make our life easy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "NtskSZXZqu3W"
      },
      "source": [
        "# @title Slides\r\n",
        "from IPython.display import HTML\r\n",
        "HTML('<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vSPvHqDTmMq4GyQy6lieNEFxq4qz1SmqC2RNoeei3_niECH53zneh8jJVYOnBIdk0Uaz7y2b9DK8V1t/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"480\" height=\"299\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E29pz3hNeQTO"
      },
      "source": [
        "\r\n",
        "Meet with your pod for 10 minutes to discuss what you learned, what was clear, and what you hope to learn more about."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "c8nOPFKTuJhA"
      },
      "source": [
        "#@markdown Tell us your thoughts about what you have learned.\n",
        "my_w2_upshot = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLzK3-6nvj9U"
      },
      "source": [
        "# Question of the week\r\n",
        "What functional forms are good or bad for representing complex functions?\r\n",
        "\r\n",
        "[answers include differentiable, hierarchical, smooth, dynamical, nonlinear]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgOQxVS1X2dB"
      },
      "source": [
        "---\r\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXd8Now_XwR7"
      },
      "source": [
        "# imports\r\n",
        "import random\r\n",
        "import pathlib\r\n",
        "\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision.datasets import ImageFolder\r\n",
        "from torch.utils.data import DataLoader, TensorDataset\r\n",
        "from torchvision.utils import make_grid\r\n",
        "from IPython.display import HTML, display\r\n",
        "\r\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "dev, torch.get_num_threads()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ZUyEQpxTSzxe"
      },
      "source": [
        "# @title Seeding for reproducibility\r\n",
        "seed = 522\r\n",
        "random.seed(seed)\r\n",
        "np.random.seed(seed)\r\n",
        "torch.manual_seed(seed)\r\n",
        "torch.cuda.manual_seed(seed)\r\n",
        "\r\n",
        "torch.backends.cudnn.deterministic = True\r\n",
        "torch.backends.cudnn.benchmark = False\r\n",
        "torch.set_deterministic(True)\r\n",
        "def seed_worker(worker_id):\r\n",
        "    worker_seed = seed % (worker_id+1)\r\n",
        "    np.random.seed(worker_seed)\r\n",
        "    random.seed(worker_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "hj8C2Cf0G0i_"
      },
      "source": [
        "# @title Dataset download\r\n",
        "%%capture\r\n",
        "!rm -r AnimalFaces32x32/\r\n",
        "!git clone https://github.com/arashash/AnimalFaces32x32\r\n",
        "!rm -r afhq/\r\n",
        "!unzip ./AnimalFaces32x32/afhq_32x32.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "oRrTcZOlXA8C"
      },
      "source": [
        "# @title Figure Settings\r\n",
        "import ipywidgets as widgets\r\n",
        "%matplotlib inline \r\n",
        "fig_w, fig_h = (8, 6)\r\n",
        "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\r\n",
        "%config InlineBackend.figure_format = 'retina'\r\n",
        "my_layout = widgets.Layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "40Qc7MFcX7Oc"
      },
      "source": [
        "# @title Helper functions\r\n",
        "def imshow(img):\r\n",
        "    img = img / 2 + 0.5     # unnormalize\r\n",
        "    npimg = img.numpy()\r\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "    plt.axis(False)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "def progress(epoch, loss, epochs=100):\r\n",
        "    return HTML(\"\"\"\r\n",
        "        <label for=\"file\">Training loss: {loss}</label>\r\n",
        "        <progress\r\n",
        "            value='{epoch}'\r\n",
        "            max='{epochs}',\r\n",
        "            style='width: 100%'\r\n",
        "        >\r\n",
        "            {epoch}\r\n",
        "        </progress>\r\n",
        "    \"\"\".format(loss=loss, epoch=epoch, epochs=epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQGBDFB0yeqV"
      },
      "source": [
        "---\r\n",
        "# Section 1: Neuron Physiology"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FNdeptL-zUnU"
      },
      "source": [
        "#@title Video: Overview and Integrate-and-Fire Neurons\n",
        "try: t1;\n",
        "except NameError: t1=time.time()\n",
        "\n",
        "video = YouTubeVideo(id=\"exTzHGfEAvU\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93MxeKdfGN7"
      },
      "source": [
        "## Section 1.1: Leaky Integrate and Fire (LIF) Neuron\r\n",
        "The basic idea of LIF neuron was proposed in 1907 by Louis Ã‰douard Lapicque, long before we understood the electrophysiology of a neuron (see a translation of [Lapicque's paper](https://pubmed.ncbi.nlm.nih.gov/17968583/) ). More details of the model can be found in the book [**Theoretical neuroscience**](http://www.gatsby.ucl.ac.uk/~dayan/book/) by Peter Dayan and Laurence F. Abbott.\r\n",
        "\r\n",
        "The model dynamic is defined with the following formula,\r\n",
        "\r\n",
        "$$\r\n",
        "\\frac{d V}{d t}=\\left\\{\\begin{array}{cc}\r\n",
        "\\frac{1}{C_{m}}\\left(-\\frac{V}{R_{m}}+I \\right) & t>t_{r e s t} \\\\\r\n",
        "0 & \\text { otherwise }\r\n",
        "\\end{array}\\right.\r\n",
        "$$\r\n",
        "\r\n",
        "Note that $-\\frac{V}{R_{m}}$ is the leakage current. When $I$ is sufficiently strong such that $V$ reaches a certain threshold value $V_{\\rm th}$, it momentarily spikes and then $V$ is reset to $V_{\\rm reset}< V_{\\rm th}$, and voltage stays at $V_{\\rm reset}$ for $\\tau_{\\rm ref}$ ms, mimicking the refractoriness of the neuron during an action potential (note that $V_{\\rm reset}$ and $\\tau_{\\rm ref}$ is assumed to be zero in the lecture):\r\n",
        "\r\n",
        "\\begin{eqnarray}\r\n",
        "V(t)=V_{\\rm reset} \\text{  for } t\\in(t_{\\text{sp}}, t_{\\text{sp}} + \\tau_{\\text{ref}}]\r\n",
        "\\end{eqnarray}\r\n",
        "\r\n",
        "where $t_{\\rm sp}$ is the spike time when $V(t)$ just exceeded $V_{\\rm th}$.\r\n",
        "\r\n",
        "Thus, the LIF model captures the facts that a neuron:\r\n",
        "- performs spatial and temporal integration of synaptic inputs \r\n",
        "- generates a spike when the voltage reaches a certain threshold\r\n",
        "- goes refractory during the action potential\r\n",
        "- has a leaky membrane \r\n",
        "\r\n",
        "For in-depth content on computational models of neuron, follow the [NMA](https://www.neuromatchacademy.org/) Week 3 Day 1 material on Real Neurons and specifically this [Tutorial](https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W3D1_RealNeurons/W3D1_Tutorial1.ipynb).\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW9mD1wC11Kw"
      },
      "source": [
        "## Exercise 1: Simulating an LIF Neuron\r\n",
        "\r\n",
        "We now write Python code to calculate equation we saw above and simulate the LIF neuron dynamics. \r\n",
        "\r\n",
        "In the cell below is given a function for LIF neuron model with it's arguments described. Note that, `simulation_time_step` and `refactory_period` have the unit `msec`. Now, it's your turn to implement this simple mathematical model of a neuron:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTydKkuOeqVc"
      },
      "source": [
        "def run_LIF(I, T = 50, dt = 0.1, t_rest = 0, tau_ref = 4,\r\n",
        "            Rm = 1, Cm = 10, Vth = 1, V_spike = 0.5):\r\n",
        "  \"\"\"\r\n",
        "  Simulate the LIF dynamics with external input current\r\n",
        "\r\n",
        "  Args:\r\n",
        "    I          : input current (mA)\r\n",
        "    T          : total time to simulate (msec)\r\n",
        "    dt         : simulation time step (msec)\r\n",
        "    t_rest     : initial refractory time\r\n",
        "    tau_ref    : refractory period (msec)\r\n",
        "    Rm         : resistance (kOhm)\r\n",
        "    Cm         : capacitance (uF)\r\n",
        "    Vth        : spike threshold (V)\r\n",
        "    V_spike    : spike delta (V)\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    time       : time points\r\n",
        "    Vm         : membrane potentials\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  time = torch.arange(0, T+dt, dt) # [TO-DO]\r\n",
        "  \r\n",
        "  # potential (V) trace over time\r\n",
        "  Vm = torch.zeros(len(time)) \r\n",
        "\r\n",
        "  # iterate over each time step\r\n",
        "  for i, t in enumerate(time):\r\n",
        "    if t > t_rest:\r\n",
        "      Vm[i] = Vm[i-1] + 1/Cm*(-Vm[i-1]/Rm + I)  * dt # [TO-DO]\r\n",
        "    if Vm[i] >= Vth:\r\n",
        "      Vm[i] += V_spike # [TO-DO]\r\n",
        "      t_rest = t + tau_ref # [TO-DO]\r\n",
        "  return time, Vm\r\n",
        "\r\n",
        "sim_time, Vm = run_LIF(1.5)\r\n",
        "# plot membrane potential trace\r\n",
        "plt.plot(sim_time, Vm)\r\n",
        "plt.title('LIF Neuron Output')\r\n",
        "plt.ylabel('Membrane Potential (V)')\r\n",
        "plt.xlabel('Time (msec)')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5hljR2LZXxS"
      },
      "source": [
        "# Section 1.2: Nonlinearity of LIF Neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh7Wnzg3ZYaY",
        "cellView": "form"
      },
      "source": [
        "#@title Video: Are Integrate-and-Fire Neurons Linear?\n",
        "\n",
        "video = YouTubeVideo(id=\"6IzHZB7xf34\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw0w47-O6Arl"
      },
      "source": [
        "## Interactive Demo: F-I Explorer for different $R_m$\r\n",
        "We know that neurons communicate by modulating the spike count. Therefore it makes sense to characterize their spike count as a function of input current. This is called the neuron's input-output transfer function (so simply F-I curve). Let's plot the neuron's F-I curve and see how it changes with respect to the membrane resistance? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "MPKolg9xjiHW"
      },
      "source": [
        "# @title\r\n",
        "\r\n",
        "# @markdown Make sure you execute this cell to enable the widget!\r\n",
        "\r\n",
        "@widgets.interact(Rm=widgets.FloatSlider(1., min=0.5, max=10., step=0.1, layout=my_layout))\r\n",
        "\r\n",
        "def plot_IF_curve(Rm):\r\n",
        "  T = 100 # total time to simulate (msec)\r\n",
        "  dt = 1 # simulation time step (msec)\r\n",
        "  Vth = 1 # spike threshold (V)\r\n",
        "  Is = torch.linspace(0, 2, 10)\r\n",
        "  spike_counts = []\r\n",
        "  for I in Is:\r\n",
        "    _, Vm = run_LIF(I, T = T, Vth = Vth, Rm=Rm)\r\n",
        "    spike_counts += [torch.sum(Vm > Vth)]\r\n",
        "\r\n",
        "  plt.plot(Is, spike_counts)\r\n",
        "  plt.title('LIF Transfer Function (I/F Curve)')\r\n",
        "  plt.ylabel('Spike count')\r\n",
        "  plt.xlabel('I (mA)')\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkvnWkvTz2O5"
      },
      "source": [
        "---\n",
        "# Section 2: The need for MLPs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tOgsH7ly5ZU1"
      },
      "source": [
        "#@title Video: The XOR Problem\n",
        "\n",
        "try: t2;\n",
        "except NameError: t2=time.time()\n",
        "\n",
        "video = YouTubeVideo(id=\"PERmPT1cOP0\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrEdLosLecm5"
      },
      "source": [
        "Here we are exposed to a limitation of linear systems, namely in solving XOR problem. One cannot draw a straight line to separate the positive (1) and negative examples(0). \n",
        "The non liearity of multilayer percepton comes in handy to solve this problem. \n",
        "We will visualize this conept in Exercise 2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJEy_D2A53SV"
      },
      "source": [
        "## Exercise 2: Solving XOR \r\n",
        "\r\n",
        "* Play with the widget and observe that you can not solve XOR\r\n",
        "* Now add one hidden layer with three units, play with the widget, and set weights by hand to solve XOR perfectly.\r\n",
        "\r\n",
        "For the second part, you should set the weights by clicking on the connections and either type the value or use the up and down keys to change it by one increment. You could also do the same for the biases by clicking on the tiny square to each neuron's bottom left.\r\n",
        "Even though there are infinitely many solutions, a neat solution when $f(x)$ is ReLU: \r\n",
        "\r\n",
        "$$y = f(x_1)+f(x_2)-f((x_1+x_2))$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ybfxBilvrWH_"
      },
      "source": [
        "# @title XOR Exercise\r\n",
        "from IPython.display import HTML\r\n",
        "HTML('<iframe width=\"1020\" height=\"660\" src=\"https://playground.arashash.com/#activation=relu&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.91390&showTestData=false&discretize=false&percTrainData=90&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\" allowfullscreen></iframe>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMJZuSjmsEQV"
      },
      "source": [
        "---\n",
        "# Section 3: Universal Function Approximation Theorem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uKiWhgZCSgY",
        "cellView": "form"
      },
      "source": [
        "#@title Video: Universal Approximation\n",
        "try: t3;\n",
        "except NameError: t3=time.time()\n",
        "\n",
        "video = YouTubeVideo(id=\"XXXYxolMVdw\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS8AGBmqlRNZ"
      },
      "source": [
        "We saw previously that multilayer perceptrons can be used to solve the XOR problem. Building off this experiment a natural question that comes to mind is - can we approximate any function using multilayer perceptrons?\n",
        "\n",
        " We learned about Universal Approximation theorem. The intuition behind the theorem is that given a sufficient number of basis functions we can approximate any function sufficiently well. These basis functions are present in the hidden layer of MLPs.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j2qcuN8x32j"
      },
      "source": [
        "## Exercise 3: Function Approximation with ReLU\r\n",
        "We learned that one hidden layer MLPs are enough to approximate any smooth function! Now let's manually fit a Sine function using ReLU activation. The idea is to set the weights iteratively so that the slope changes in the new sample's direction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVSelFbmFIE1"
      },
      "source": [
        "N_test = 1000\r\n",
        "x_test = torch.linspace(0, 2*np.pi, N_test).view(-1, 1)\r\n",
        "y_test = torch.sin(x_test)\r\n",
        "plt.plot(x_test, y_test, label='ground truth')\r\n",
        "\r\n",
        "N_train = 10\r\n",
        "x_train = torch.linspace(0, 2*np.pi, N_train).view(-1, 1)\r\n",
        "y_train = torch.sin(x_train)\r\n",
        "\r\n",
        "W1 = torch.ones(1, N_train)  # [TO-DO]\r\n",
        "b1 = - x_train.view(N_train)  # [TO-DO]\r\n",
        "\r\n",
        "W2 = torch.zeros(N_train, 1)  # [TO-DO]\r\n",
        "prev_slope = 0\r\n",
        "for i in range(N_train-1):\r\n",
        "  delta_x = x_train[i+1] - x_train[i]  # [TO-DO]\r\n",
        "  slope = (y_train[i+1] - y_train[i]) / delta_x  # [TO-DO]\r\n",
        "  W2[i] = slope - prev_slope  # [TO-DO]\r\n",
        "  prev_slope = slope\r\n",
        "\r\n",
        "y_hat = torch.relu(b1 + x_test @ W1) @ W2  # [TO-DO]\r\n",
        "\r\n",
        "plt.plot(x_test, y_hat, label='estimated')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('x')\r\n",
        "plt.ylabel('y(x)')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eglZ3_zBEKHR"
      },
      "source": [
        "# Section ?: Completeness proof sketch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "f7_oWnsqERUk"
      },
      "source": [
        "#@title Video: Making Multi-Layer Perceptrons\n",
        "video = YouTubeVideo(id=\"bAhrg8Z8_r8\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifiNLt8AoqQx"
      },
      "source": [
        "In the previous segment we implemented a function to approximate any smooth function using MLPs. We saw that using Lipschitz continuity we can prove that our approximation is mathematically correct. MLPs are fascinating but before we get into the details on how to design them familiarize yourself with some basic terminology of MLPs- layer, neuron, depth, widht, weight, bias and activation function. Armed with these ideas we can now begin to design a MLP given it's input, hidden and output size.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b37WDpWIUNU"
      },
      "source": [
        "# MLPs in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it4t-UVzJeop",
        "cellView": "form"
      },
      "source": [
        "#@title Video 5:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_TpUE0cHW1K"
      },
      "source": [
        "## Exercise 4: Implement a general-purpose MLP in Pytorch\r\n",
        "The objective is to design an MLP with these properties:\r\n",
        "* works with any input (1D, 2D, etc.)\r\n",
        "* construct any number of given hidden layers using ModuleList\r\n",
        "* use the same given activation function in all hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsq7SdqHx8a"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self, actv, num_inputs, hidden_units, num_outputs):\r\n",
        "        super(Net, self).__init__()\r\n",
        "\r\n",
        "        exec('self.actv = nn.%s'%actv)   # [TO-DO]\r\n",
        "\r\n",
        "        self.layers = nn.ModuleList()\r\n",
        "        for i in range(len(hidden_units)):\r\n",
        "          next_num_inputs = hidden_units[i] \r\n",
        "          self.layers += [nn.Linear(num_inputs, next_num_inputs)]   # [TO-DO]\r\n",
        "          num_inputs = next_num_inputs\r\n",
        "\r\n",
        "        self.out = nn.Linear(num_inputs, num_outputs)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # flattening\r\n",
        "        x = x.view(x.shape[0], -1)   # [TO-DO]\r\n",
        "\r\n",
        "        for layer in self.layers:\r\n",
        "          x = self.actv(layer(x))  # [TO-DO]\r\n",
        "        x = self.out(x) # [TO-DO]\r\n",
        "        return x\r\n",
        "# test it\r\n",
        "Net(actv='LeakyReLU(0.1)',\r\n",
        "    num_inputs = 2,\r\n",
        "    hidden_units = [100, 10, 5],\r\n",
        "    num_outputs = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPWedinyGHiY"
      },
      "source": [
        "# ReLU in practice\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdQ08YiiGk06",
        "cellView": "form"
      },
      "source": [
        "#@title Video 6:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyOmkogLKuDt"
      },
      "source": [
        "## Exercise 5: Benchmark Various ReLU Implementation\r\n",
        "Implement and benchmark at least three different ReLU implementations. Use `%timeit` with test number 10 and repeat number 3. Which then takes an average of 10 runs and repeats 3 times, and reports the lowest (best) average time.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jzG8GWvKtLt"
      },
      "source": [
        "x = torch.rand((10000, 10000)).to(dev) - 0.5\r\n",
        "print(\"Pytorch : \", end='')\r\n",
        "%timeit -n10 -r3 torch.relu(x)\r\n",
        "print('-----------------------------------------------')\r\n",
        "\r\n",
        "print(\"First: \", end='')\r\n",
        "%timeit -n10 -r3 torch.max(x, torch.zeros_like(x))   # [TO-DO]\r\n",
        "print('-----------------------------------------------')\r\n",
        "\r\n",
        "print(\"Second: \", end='')\r\n",
        "%timeit -n10 -r3 x * (x > 0)   # [TO-DO]\r\n",
        "print('-----------------------------------------------')\r\n",
        "\r\n",
        "print(\"Third: \", end='')\r\n",
        "%timeit -n10 -r3 x[x<0] = 0   # [TO-DO]\r\n",
        "print('-----------------------------------------------')\r\n",
        "\r\n",
        "print(\"Forth: \", end='')\r\n",
        "%timeit -n10 -r3 (torch.abs(x) + x) / 2   # [TO-DO]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VDVqxxaJlz8"
      },
      "source": [
        "# Classification with MLPs\r\n",
        "Two potential loss functions\r\n",
        "## CrossEntropyLoss\r\n",
        "This criterion expects a class index in the range $[0, C-1]$ as the target for each value of a $1D$ tensor of size minibatch. There are other optional parameters like class weights and class ignores. Check the documentation here for more detail. Then in the simplest case, it calculates this,\r\n",
        "\r\n",
        "$$\r\n",
        "\\operatorname{loss}(x, \\text { class })=-\\log \\left(\\frac{\\exp (x[\\text { class }])}{\\sum_{j} \\exp (x[j])}\\right)=-x[\\text { class }]+\\log \\left(\\sum_{j} \\exp (x[j])\\right)\r\n",
        "$$\r\n",
        "\r\n",
        "## MultiMarginLoss\r\n",
        "The loss corresponding to class j is calculated as follows,\r\n",
        "$$\r\n",
        "l_j(x, y)=\\sum_{j\\neq y} \\max (0, \\operatorname{margin}-x[y]+x[j])\r\n",
        "$$\r\n",
        "Then it is averaged over all the class elements and all the mini-batch samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gXlMu7ouaKrb"
      },
      "source": [
        "#@title Video 7:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCvA5etP2GOy"
      },
      "source": [
        "## Exercise 6: Simulate a Spiral Classification Dataset\r\n",
        "Let's turn this fancy-looking equation into a classification dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTdmdB6oD0KU"
      },
      "source": [
        "$$\r\n",
        "\\begin{array}{c}\r\n",
        "X_{k}(t)=t\\left(\\begin{array}{c}\r\n",
        "\\sin \\left[\\frac{2 \\pi}{K}\\left(2 t+k-1\\right)\\right]+\\mathcal{N}\\left(0, \\sigma^{2}\\right) \\\\\r\n",
        "\\cos \\left[\\frac{2 \\pi}{K}\\left(2 t+k-1\\right)\\right]+\\mathcal{N}\\left(0, \\sigma^{2}\\right) \r\n",
        "\\end{array}\\right)\r\n",
        "\\end{array}, \\quad 0 \\leq t \\leq 1, \\quad k=1, \\ldots, K\r\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utfWXn81FHT4"
      },
      "source": [
        "K = 4\r\n",
        "sigma = 0.4\r\n",
        "N = 1000\r\n",
        "t = torch.linspace(0, 1, N)\r\n",
        "X = torch.zeros(K*N, 2)\r\n",
        "y = torch.zeros(K*N)\r\n",
        "for k in range(K):\r\n",
        "  X[k*N:(k+1)*N, 0] = t*(torch.sin(2*np.pi/K*(2*t+k)) + sigma**2*torch.randn(N))   # [TO-DO]\r\n",
        "  X[k*N:(k+1)*N, 1] = t*(torch.cos(2*np.pi/K*(2*t+k)) + sigma**2*torch.randn(N))   # [TO-DO]\r\n",
        "  y[k*N:(k+1)*N] = k   # [TO-DO]\r\n",
        "\r\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\r\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUhAlD-XcbTa"
      },
      "source": [
        "# Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "eY2VN0MfcSPN"
      },
      "source": [
        "#@title Video 8:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3RZa-charD2"
      },
      "source": [
        "## Exercise 7: Implement it for Spiral Dataset\r\n",
        "Steps to follow: \r\n",
        "  * Dataset shuffle\r\n",
        "  * Train/Test split\r\n",
        "  * Dataloader definition\r\n",
        "  * Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCS2dEqPfiA"
      },
      "source": [
        "# Shuffling\r\n",
        "shuffled_indeces = torch.randperm(K*N)   # [TO-DO]\r\n",
        "X = X[shuffled_indeces]\r\n",
        "y = y[shuffled_indeces]\r\n",
        "\r\n",
        "# Test Train splitting\r\n",
        "test_size = int(0.2*N)   # [TO-DO]\r\n",
        "X_test = X[:test_size]\r\n",
        "y_test = y[:test_size]\r\n",
        "X_train = X[test_size:]\r\n",
        "y_train = y[test_size:]\r\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\r\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMYnhid1bCyq"
      },
      "source": [
        "And making a Pytorch data loader out of it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPJNQtOOgC3E"
      },
      "source": [
        "batch_size = 128\r\n",
        "test_data = TensorDataset(X_test, y_test)\r\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size,\r\n",
        "                         shuffle=False, num_workers=0)\r\n",
        "\r\n",
        "train_data = TensorDataset(X_train, y_train)\r\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, drop_last=True,\r\n",
        "                        shuffle=True, num_workers=0, worker_init_fn=seed_worker)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW95_EQp1QHx"
      },
      "source": [
        "def train_test_classification(net, criterion, optimizer,\r\n",
        "                              train_loader, test_loader,\r\n",
        "                              num_epochs=1, verbose=True, \r\n",
        "                              training_plot=False):\r\n",
        "  if verbose:\r\n",
        "    progress_bar = display(progress(0, 0, num_epochs), display_id=True)\r\n",
        "\r\n",
        "  net.train()   # [TO-DO]\r\n",
        "  training_losses = []\r\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\r\n",
        "      running_loss = 0.0\r\n",
        "      for i, data in enumerate(train_loader, 0):\r\n",
        "          # get the inputs; data is a list of [inputs, labels]\r\n",
        "          inputs, labels = data\r\n",
        "          inputs = inputs.to(dev).float()    # [TO-DO]\r\n",
        "          labels = labels.to(dev).long()   # [TO-DO]\r\n",
        "\r\n",
        "          # zero the parameter gradients\r\n",
        "          optimizer.zero_grad()   # [TO-DO]\r\n",
        "\r\n",
        "          # forward + backward + optimize\r\n",
        "          outputs = net(inputs)   # [TO-DO]\r\n",
        "\r\n",
        "          loss = criterion(outputs, labels)   # [TO-DO]\r\n",
        "          loss.backward()   # [TO-DO]\r\n",
        "          optimizer.step()   # [TO-DO]\r\n",
        "\r\n",
        "          # print statistics\r\n",
        "          if verbose:\r\n",
        "            training_losses += [loss.item()]\r\n",
        "            running_loss += loss.item()\r\n",
        "            if i % 10 == 9:    # update every 10 mini-batches\r\n",
        "                progress_bar.update(progress(epoch+1, running_loss / 10, num_epochs))\r\n",
        "                running_loss = 0.0\r\n",
        "\r\n",
        "  net.eval()   # [TO-DO]\r\n",
        "  def test(data_loader):\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    for data in data_loader:\r\n",
        "        inputs, labels = data\r\n",
        "        inputs = inputs.to(dev).float()\r\n",
        "        labels = labels.to(dev).long()\r\n",
        "\r\n",
        "        outputs = net(inputs)\r\n",
        "        _, predicted = torch.max(outputs, 1)   # [TO-DO]\r\n",
        "        total += labels.size(0)   # [TO-DO]\r\n",
        "        correct += (predicted == labels).sum().item()   # [TO-DO]\r\n",
        "\r\n",
        "    acc = 100 * correct / total    # [TO-DO]\r\n",
        "    return total, acc\r\n",
        "\r\n",
        "  train_total, train_acc = test(train_loader)\r\n",
        "  test_total, test_acc = test(test_loader)\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "    print('Accuracy on the %d training samples: %0.2f %%' % (train_total, train_acc))\r\n",
        "    print('Accuracy on the %d testing samples: %0.2f %%' % (test_total, test_acc))\r\n",
        "\r\n",
        "  if training_plot:\r\n",
        "    plt.plot(training_losses)\r\n",
        "    plt.xlabel('Batch')\r\n",
        "    plt.ylabel('Training loss')\r\n",
        "    plt.show()\r\n",
        "  \r\n",
        "  return train_acc, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEGwbZrUfpZu"
      },
      "source": [
        "net = Net('ReLU()', X_train.shape[1], [128], K).to(dev)    # [TO-DO] \r\n",
        "criterion = nn.CrossEntropyLoss()    # [TO-DO]\r\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)\r\n",
        "num_epochs = 100\r\n",
        "_, _ = train_test_classification(net, criterion, optimizer, train_loader,\r\n",
        "                                 test_loader, num_epochs=num_epochs,\r\n",
        "                                 training_plot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S2ZU9tyeaML"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "9Y2J8pw3ejPZ"
      },
      "source": [
        "#@title Video 9:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_HvMx0thX42"
      },
      "source": [
        "## Exercise 8: Implement decision map visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elWAOswugLak"
      },
      "source": [
        "def sample_grid(M=500, x_max = 2.0):\r\n",
        "  ii, jj = torch.meshgrid(torch.linspace(-x_max, x_max,M),\r\n",
        "                          torch.linspace(-x_max, x_max, M))\r\n",
        "  X_all = torch.cat([ii.unsqueeze(-1),\r\n",
        "                     jj.unsqueeze(-1)],\r\n",
        "                     dim=-1).view(-1, 2)    # [TO-DO]\r\n",
        "  return X_all\r\n",
        "\r\n",
        "def plot_decision_map(X_all, y_pred, X_test, y_test, M=500, x_max = 2.0, eps = 1e-3):\r\n",
        "  decision_map = torch.argmax(y_pred, dim=1)    # [TO-DO]\r\n",
        "\r\n",
        "  for i in range(len(X_test)):\r\n",
        "    indeces = (X_all[:, 0] - X_test[i, 0])**2 + (X_all[:, 1] - X_test[i, 1])**2 < eps    # [TO-DO]\r\n",
        "    decision_map[indeces] = (K + y_test[i]).long()    # [TO-DO]\r\n",
        "\r\n",
        "  decision_map = decision_map.view(M, M).cpu()\r\n",
        "  plt.imshow(decision_map, extent=[-x_max, x_max, -x_max, x_max], cmap='jet')\r\n",
        "  plt.plot()\r\n",
        "\r\n",
        "X_all = sample_grid()\r\n",
        "y_pred = net(X_all)\r\n",
        "plot_decision_map(X_all, y_pred, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}